# Introduction 
These artifacts are part of a blog that describes a sample use case for predicting POS sales across stores, coordinated with inventory and supply chain data.
PySpark is used for data and ML pipelines on Databricks, orchestrated with Control-M from BMC, to predict POS and forecast inventory items in Production.

# Platform and Components 
•	Databricks Intelligent Data Platform on Azure
•	PySpark
•	Python Pandas library
•	Python Seaborn library for data visualization
•	Jupyter Notebooks on Databricks
•	Parquet and Delta file format
# Project Artifacts
•	Code for data ingestion, processing, ML training and serving, saving forecasted results to Databricks Lakehouse in delta format.
•	Code for workflow and orchestration with Control-M to coordinate all the activities and tasks and handle failure scenarios